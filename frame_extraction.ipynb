{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting frame out of stored video.\n",
    "\n",
    "- Source Link:https://www.geeksforgeeks.org/python-program-extract-frames-using-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program To Read video \n",
    "# and Extract Frames \n",
    "import cv2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCv library can be used to perform multiple operations on videos. Letâ€™s try to do something interesting using CV2.\n",
    "- Take a video as input and break the video into frame by frame and save those frame. \n",
    "\n",
    "**Operations can perform form on the Video**\n",
    "\n",
    "- Now, number of operations can be performed on these frames. \n",
    "\n",
    "    - Like reversing the video file or crop the video etc. \n",
    "    - For playing video in reverse mode, we need only to store the frames in a list and iterate reverse in the list of      frames.\n",
    "    - Use reverse method of the list for reversing the order of frames in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames \n",
    "def FrameCapture(path): \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "# Used as counter variable \n",
    "    count = 0\n",
    "\n",
    "# checks whether frames were extracted \n",
    "    success = 1\n",
    "\n",
    "    while success: \n",
    "        success, image = vidObj.read() \n",
    "\n",
    "# Saves the frames with frame-count \n",
    "        cv2.imwrite(\"frame%d.jpg\" % count, image) \n",
    "        count += 1\n",
    "\n",
    "# Driver Code \n",
    "if __name__ == '__main__': \n",
    "    FrameCapture(\"C:\\\\Users\\\\aditya\\\\Videos\\\\Sample_Videos\\\\SampleVideo_1.mp4\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this code will save the frames inside the same folder as the notebook.\n",
    "\n",
    "**Example of the output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](frame10.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resizing the image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SOURCE: https://stackoverflow.com/questions/41598916/resize-the-image-in-jupyter-notebook-using-markdown\n",
    "**Syntax inside a markdown: \n",
    "- <img src=\"image.JPG\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "- don't run this tab.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"frame10.JPG\" alt=\"Drawing\" style=\"width: 500px;\"/>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame Extraction from  real time videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameCapture(path): \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "\n",
    "# Used as counter variable \n",
    "    count = 0\n",
    "\n",
    "# checks whether frames were extracted \n",
    "    success = 1\n",
    "\n",
    "    while success: \n",
    "        success, image = vidObj.read() \n",
    "\n",
    "# Saves the frames with frame-count \n",
    "        cv2.imwrite(\"frame%d.jpg\" % count, image) \n",
    "        count += 1\n",
    "\n",
    "# Driver Code \n",
    "if __name__ == '__main__': \n",
    "    FrameCapture(0) \n",
    "    \n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# cap=cv2.VideoCapture(0) # 0 is for inbuilt camera\n",
    "\n",
    "# while True:\n",
    "#     ret,frame=cap.read()\n",
    "#     gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     cv2.imshow('frame',frame)\n",
    "#     cv2.imshow('gray',gray)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "# ## Press q and the loop will get off.        \n",
    "#         break\n",
    "# cap.release()\n",
    "# #out.release()\n",
    "# cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Code For saving the images to particular folder.\n",
    "- as cv2.imwrite saves the images inside the default folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOURCE: https://stackoverflow.com/questions/41586429/opencv-saving-images-to-a-particular-folder-of-choice/41587740\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "img=cv2.imread('image_with_text.jpg',1) \n",
    "# 1 means colored image\n",
    "# Remember OpenCV is in BGR \n",
    "# Therefore regular colored image will be somehow distorted.\n",
    "path='D:\\\\GITHUB\\\\aws-rekognition\\\\Frames'\n",
    "cv2.imwrite(os.path.join(path,\"frame.jpg\"),img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output:\n",
    "\n",
    "- Code is working.\n",
    "- image inside default folder is copied into the mentioned path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The initial code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "vidobj=cv2.VideoCapture(0)\n",
    "success=1\n",
    "count=0\n",
    "while True:\n",
    "    success,image=vidobj.read()\n",
    "    cv2.imshow('frame',image)\n",
    "    cv2.imwrite(\"frame%d.jpg\" % count,image)\n",
    "    count+=1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vidobj.release()\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "\n",
    "- The code is running\n",
    "- Frames are saved inside the folder\n",
    "- webcam initially was not terminating but after using cv2.imshow and calibration it worked.\n",
    "- Now i'll try to save the frames inside a specific folder for better use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt on the Frame Extraction of real time videos. \n",
    "\n",
    "- Now Saving the frames inside a particular folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "vidobj=cv2.VideoCapture(0)\n",
    "success=1\n",
    "count=0\n",
    "path='D:\\\\GITHUB\\\\aws-rekognition\\\\Frames\\\\realtime_frame'\n",
    "\n",
    "\n",
    "#path='C:\\\\Users\\\\aditya\\\\Pictures\\\\Saved Pictures'   \n",
    "#Used it in order to view the frames.                    \n",
    "# As gitignore is created frames in the Frame folder cannot be viewed.\n",
    "\n",
    "\n",
    "# Now we just have to change the path and the source code will take care of the rest.\n",
    "while True:\n",
    "    success,image=vidobj.read()\n",
    "    cv2.imshow('frame',image)\n",
    "    cv2.imwrite(os.path.join(path,\"frame%d.jpg\" % count),image)\n",
    "    count+=1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vidobj.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFECT WORKING....!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXAMPLE OF OUTPUT:\n",
    "\n",
    "- One of the frame out of 130 frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](frame59.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example \n",
    "\n",
    "$$Delivery-Slip$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of the frame out 100 frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](frame68_del_receipt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverting Frames into grayscale.\n",
    "\n",
    "- Hoping for better quality while reading and cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "vidobj=cv2.VideoCapture(0)\n",
    "success=1\n",
    "count=0\n",
    "#path='D:\\\\GITHUB\\\\aws-rekognition\\\\Frames\\\\realtime_frame'\n",
    "\n",
    "\n",
    "path='C:\\\\Users\\\\aditya\\\\Pictures\\\\Saved Pictures'   \n",
    "#Used it in order to view the frames.                    \n",
    "# As gitignore is created frames in the Frame folder cannot be viewed.\n",
    "\n",
    "\n",
    "# Now we just have to change the path and the source code will take care of the rest.\n",
    "while True:\n",
    "    success,image=vidobj.read()\n",
    "    #gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('GRAY',gray)\n",
    "    cv2.imwrite(os.path.join(path,\"frame%d.jpg\" % count),gray)\n",
    "    count+=1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vidobj.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Perfectly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRAYSCALE DELIVERY SLIP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](frame113_grayscale.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDGE DETECTION ON GRAYSCALE IMAGE:\n",
    "\n",
    "- Trying out edge detection on a grayscale image and storing in the default folder.\n",
    "- SOURCE: https://www.geeksforgeeks.org/real-time-edge-detection-using-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import cv2 \n",
    "# import numpy as np \n",
    "\n",
    "# FILE_NAME = 'volleyball.jpg'\n",
    "# try: \n",
    "# \t# Read image from disk. \n",
    "# \timg = cv2.imread(FILE_NAME) \n",
    "\n",
    "# \t# Canny edge detection. \n",
    "# \tedges = cv2.Canny(img, 100, 200) \n",
    "\n",
    "# \t# Write image back to disk. \n",
    "# \tcv2.imwrite('result.jpg', edges) \n",
    "# except IOError: \n",
    "# \tprint ('Error while reading files !!!') \n",
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file=cv2.imread('frame113_grayscale.jpg')\n",
    "#Canny Edge Detection.\n",
    "edge=cv2.Canny(file,100,200)\n",
    "cv2.imwrite('edge_detected.jpg',edge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output:\n",
    "\n",
    "**EDGE-DETECTED-IMAGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](edge_detected.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Perspective Transform!\n",
    "\n",
    "- Image as well as real time video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9642315af690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwarped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfour_point_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# show the original and warped images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pts' is not defined"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('frame114.jpg',1)\n",
    "def order_points(pts):\n",
    "\t# initialzie a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\n",
    "\t# compute the width of the new image, which will be the\n",
    "\t# maximum distance between bottom-right and bottom-left\n",
    "\t# x-coordiates or the top-right and top-left x-coordinates\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "\t# return the warped image\n",
    "\treturn warped\n",
    "\n",
    "warped = four_point_transform(image, pts)\n",
    " \n",
    "# show the original and warped images\n",
    "cv2.imshow(\"Original\", image)\n",
    "cv2.imshow(\"Warped\", warped)\n",
    "cv2.waitKey(0)\n",
    "   \n",
    "# #from pyimagesearch.transform import four_point_transform\n",
    "# #import numpy as np\n",
    "# import argparse\n",
    "# #import cv2\n",
    " \n",
    "# # construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", help = \"path to the image file\")\n",
    "# ap.add_argument(\"-c\", \"--coords\",\n",
    "# \thelp = \"comma seperated list of source points\")\n",
    "# args = vars(ap.parse_args())\n",
    " \n",
    "# # load the image and grab the source coordinates (i.e. the list of\n",
    "# # of (x, y) points)\n",
    "# # NOTE: using the 'eval' function is bad form, but for this example\n",
    "# # let's just roll with it -- in future posts I'll show you how to\n",
    "# # automatically determine the coordinates without pre-supplying them\n",
    "\n",
    "\n",
    " \n",
    "# # apply the four point tranform to obtain a \"birds eye view\" of\n",
    "# # the image\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "image=cv2.imread('frame114.jpg',1)\n",
    "#cv2.imshow(\"a\",image)\n",
    "#cv2.waitKey(2000)\n",
    "#cv2.destroyAllWindows()\n",
    "print(image.shape)\n",
    "\n",
    "\n",
    "\n",
    "#TOP LEFT --> TOP RIGHT --> BOTTOM LEFT--> BOTTOM RIGHT.\n",
    "x=cv2.circle(image,(101,65),5,(0,255,0),-1)\n",
    "#will draw a circle at Coordinates (100,100) of size 5 of color (green),no change in image color)\n",
    "\n",
    "\n",
    "y=cv2.circle(image,(107,440),5,(0,255,0),-1)\n",
    "z=cv2.circle(image,(360,50),5,(0,255,0),-1)\n",
    "h= cv2.circle(image,(380,425),5,(0,255,0),-1)\n",
    "\n",
    "\n",
    "pts1=np.float32([[101,65],[360,50],[107,440],[380,425]])\n",
    "pts2=np.float32([[0,0],[400,0],[0,600],[400,600]])\n",
    "\n",
    "matrix=cv2.getPerspectiveTransform(pts1,pts2)\n",
    "result=cv2.warpPerspective(h,matrix,(400,600))\n",
    "\n",
    "\n",
    "#cv2.imshow('b',z)\n",
    "cv2.imshow('b',result)\n",
    "\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

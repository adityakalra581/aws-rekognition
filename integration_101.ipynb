{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "\n",
    "\n",
    "vidobj=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _,frame=vidobj.read()\n",
    "    # will draw a rectangle on the real time video.\n",
    "    cv2.rectangle(frame, (100,0),(600,650),(255,255,255),2)  # Vertical dominating.\n",
    "    #cv2.rectangle(frame, (0,100),(650,400),(255,255,255),2)   # Horizontal dominating.\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        break\n",
    "vidobj.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording a video!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "#fourcc = cv2.cv.CV_FOURCC(*'DIVX')\n",
    "#out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "out = cv2.VideoWriter('output.avi', -1, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.rectangle(frame, (100,0),(600,650),(255,255,255),2)\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,0)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "        \n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requires Flipping.\n",
    "\n",
    "- Video saved and streamed both are rotated 180 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording a video using OpenCV\n",
    "\n",
    "- Source: https://www.youtube.com/watch?v=1eHQIu4r0Bc\n",
    "- code: https://www.codingforentrepreneurs.com/blog/how-to-record-video-in-opencv-python/\n",
    "- Link for downloading fourcc: http://www.fourcc.org/downloads/3ivx-mpeg-4-for-wind-4/start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "filename = 'video.avi'\n",
    "frames_per_second = 24.0\n",
    "res = '480p'\n",
    "\n",
    "# Set resolution for the video capture\n",
    "# Function adapted from https://kirr.co/0l6qmh\n",
    "def change_res(cap, width, height):\n",
    "    cap.set(3, width)\n",
    "    cap.set(4, height)\n",
    "\n",
    "# Standard Video Dimensions Sizes\n",
    "STD_DIMENSIONS =  {\n",
    "    \"480p\": (640, 480),\n",
    "    \"720p\": (1280, 720),\n",
    "    \"1080p\": (1920, 1080),\n",
    "    \"4k\": (3840, 2160),\n",
    "}\n",
    "\n",
    "\n",
    "# grab resolution dimensions and set video capture to it.\n",
    "def get_dims(cap, res='1080p'):\n",
    "    width, height = STD_DIMENSIONS[\"480p\"]\n",
    "    if res in STD_DIMENSIONS:\n",
    "        width,height = STD_DIMENSIONS[res]\n",
    "    ## change the current caputre device\n",
    "    ## to the resulting resolution\n",
    "    change_res(cap, width, height)\n",
    "    return width, height\n",
    "\n",
    "# Video Encoding, might require additional installs\n",
    "# Types of Codes: http://www.fourcc.org/codecs.php\n",
    "VIDEO_TYPE = {\n",
    "    'avi': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "    #'mp4': cv2.VideoWriter_fourcc(*'H264'),\n",
    "    'mp4': cv2.VideoWriter_fourcc(*'XVID'),\n",
    "}\n",
    "\n",
    "def get_video_type(filename):\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    if ext in VIDEO_TYPE:\n",
    "        return  VIDEO_TYPE[ext]\n",
    "    return VIDEO_TYPE['avi']\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "out = cv2.VideoWriter(filename, get_video_type(filename), 25, get_dims(cap, res))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.rectangle(frame, (100,0),(600,650),(255,255,255),2)\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# img=cv2.imread('image_with_text.jpg',1) \n",
    "# # 1 means colored image\n",
    "# # Remember OpenCV is in BGR \n",
    "# # Therefore regular colored image will be somehow distorted.\n",
    "# path='D:\\\\GITHUB\\\\aws-rekognition\\\\Frames'\n",
    "# cv2.imwrite(os.path.join(path,\"frame.jpg\"),img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Key Frame:\n",
    "\n",
    "Source: https://github.com/amanwalia92/KeyFramesExtraction/blob/master/scene_div.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditya\\Anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "print(sys.executable)\n",
    "#Setting fixed threshold criteria\n",
    "USE_THRESH = False\n",
    "#fixed threshold value\n",
    "THRESH = 0.4\n",
    "#Setting fixed threshold criteria\n",
    "USE_TOP_ORDER = True\n",
    "#Setting local maxima criteria\n",
    "USE_LOCAL_MAXIMA = False\n",
    "#Number of top sorted frames\n",
    "NUM_TOP_FRAMES = 20\n",
    "\n",
    "#Video path of the source file\n",
    "#videopath = \"D:\\\\GITHUB\\\\aws-rekognition\\\\ouput.avi\"\n",
    "videopath=\"D:\\\\GITHUB\\\\aws-rekognition\\\\video.avi\"\n",
    "#Directory to store the processed frames\n",
    "dir = \"C:\\\\Users\\\\aditya\\\\Pictures\\\\Key_frames\"\n",
    "#smoothing window size\n",
    "len_window = int(5)\n",
    "\n",
    "\n",
    "def smooth(x, window_len=13, window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "\n",
    "    import numpy as np    \n",
    "    t = np.linspace(-2,2,0.1)\n",
    "    x = np.sin(t)+np.random.randn(len(t))*0.1\n",
    "    y = smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    " \n",
    "    TODO: the window parameter could be the window itself if an array instead of a string   \n",
    "    \"\"\"\n",
    "    print(len(x), window_len)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError # \"smooth only accepts 1 dimension arrays.\"\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError # \"Input vector needs to be bigger than window size.\"\n",
    "\n",
    "    if window_len < 3:\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError #\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "\n",
    "    s = np.r_[2 * x[0] - x[window_len:1:-1],\n",
    "              x, 2 * x[-1] - x[-1:-window_len:-1]]\n",
    "    #print(len(s))\n",
    "\n",
    "    if window == 'flat':  # moving average\n",
    "        w = np.ones(window_len, 'd')\n",
    "    else:\n",
    "        w = getattr(np, window)(window_len)\n",
    "    y = np.convolve(w / w.sum(), s, mode='same')\n",
    "    return y[window_len - 1:-window_len + 1]\n",
    "\n",
    "#Class to hold information about each frame\n",
    "\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, id, frame, value):\n",
    "        self.id = id\n",
    "        self.frame = frame\n",
    "        self.value = value\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.id == other.id:\n",
    "            return self.id < other.id\n",
    "        return self.id < other.id\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return other.__lt__(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id and self.id == other.id\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "\n",
    "def rel_change(a, b):\n",
    "    x = (b - a) / max(a, b)\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "#print(\"Video :\" + videopath)\n",
    "#print(\"Frame Directory: \" + dir)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(str(videopath))\n",
    "\n",
    "\n",
    "curr_frame = None\n",
    "prev_frame = None\n",
    "\n",
    "frame_diffs = []\n",
    "frames = []\n",
    "ret, frame = cap.read()\n",
    "i = 1\n",
    "\n",
    "while(ret):\n",
    "    luv = cv2.cvtColor(frame, cv2.COLOR_BGR2LUV)\n",
    "    curr_frame = luv\n",
    "    if curr_frame is not None and prev_frame is not None:\n",
    "        #logic here\n",
    "        diff = cv2.absdiff(curr_frame, prev_frame)\n",
    "        count = np.sum(diff)\n",
    "        frame_diffs.append(count)\n",
    "        frame = Frame(i, frame, count)\n",
    "        frames.append(frame)\n",
    "    prev_frame = curr_frame\n",
    "    i = i + 1\n",
    "    ret, frame = cap.read()\n",
    "#     cv2.rectangle(frame, (100,0),(600,650),(255,255,255),2)\n",
    "#     cv2.imshow('frame',frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "cap.release()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "if USE_TOP_ORDER:\n",
    "    # sort the list in descending order\n",
    "    frames.sort(key=operator.attrgetter(\"value\"), reverse=True)\n",
    "    for keyframe in frames[:NUM_TOP_FRAMES]:\n",
    "        name = \"frame_\" + str(keyframe.id) + \".jpg\"\n",
    "        cv2.imwrite(dir + \"/\" + name, keyframe.frame)\n",
    "\n",
    "if USE_THRESH:\n",
    "    print(\"Using Threshold\")\n",
    "    for i in range(1, len(frames)):\n",
    "        if (rel_change(np.float(frames[i - 1].value), np.float(frames[i].value)) >= THRESH):\n",
    "            #print(\"prev_frame:\"+str(frames[i-1].value)+\"  curr_frame:\"+str(frames[i].value))\n",
    "            name = \"frame_\" + str(frames[i].id) + \".jpg\"\n",
    "            cv2.imwrite(dir + \"/\" + name, frames[i].frame)\n",
    "\n",
    "\n",
    "if USE_LOCAL_MAXIMA:\n",
    "    print(\"Using Local Maxima\")\n",
    "    diff_array = np.array(frame_diffs)\n",
    "    sm_diff_array = smooth(diff_array, len_window)\n",
    "    frame_indexes = np.asarray(argrelextrema(sm_diff_array, np.greater))[0]\n",
    "    for i in frame_indexes:\n",
    "        name = \"frame_\" + str(frames[i - 1].id) + \".jpg\"\n",
    "        #print(dir+name)\n",
    "        cv2.imwrite(dir + name, frames[i - 1].frame)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(40, 20))\n",
    "# plt.locator_params(numticks=100)\n",
    "# plt.stem(sm_diff_array)\n",
    "# plt.savefig(dir + 'plot.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working Nice on good quality recorded video but not on web cam video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pathetic performance on web cam videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
